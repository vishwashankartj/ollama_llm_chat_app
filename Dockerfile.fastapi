# Use an appropriate base image, such as python
FROM python:3.10-slim

# Install system dependencies (like curl) and Ollama
RUN apt-get update && apt-get install -y curl

# Install Ollama
RUN curl -sSL https://ollama.com/install.sh | bash

# Set the working directory for your FastAPI app
WORKDIR /app

# Install Python dependencies for FastAPI
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy the rest of your FastAPI app
COPY . .

# Expose the required port (e.g., 5000)
EXPOSE 5000

# Command to run FastAPI app and start the model
CMD ["bash", "-c", "ollama run llama3.2:1b && uvicorn app:app --host 0.0.0.0 --port 5000"]
