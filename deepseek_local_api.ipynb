{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from fastapi import FastAPI\n",
    "# import ollama\n",
    "\n",
    "# app = FastAPI()\n",
    "\n",
    "# @app.post(\"/generate\")\n",
    "# def generate(prompt: str):\n",
    "#     response = ollama.chat(model=\"deepseek-coder\", messages=[{\"role\": \"user\", \"content\": prompt}])\n",
    "#     return {\"response\": response['message']['content']}\n",
    "\n",
    "# import nest_asyncio\n",
    "# import uvicorn\n",
    "\n",
    "# nest_asyncio.apply()  # Allows running uvicorn inside Jupyter\n",
    "# uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install ollama\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## with mongodb integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils import mongo_module\n",
    "\n",
    "# URI = mongo_module.mongo_creds_from_config()\n",
    "# client = mongo_module.create_mongo_client(URI)\n",
    "\n",
    "# if client:\n",
    "#     sample_data = {\"name\": \"John Doe\", \"age\": 30, \"city\": \"New York\"}\n",
    "#     mongo_module.insert_data(client, \"testDB\", \"users\", sample_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [92962]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to MongoDB successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cq/hc047wm16ks3ystn97nbx3980000gn/T/ipykernel_92962/665709683.py:26: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  timestamp = datetime.utcnow()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inserted successfully with ID: 67b26ef452428ec61e7289f8\n",
      "INFO:     127.0.0.1:54801 - \"POST /generate HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cq/hc047wm16ks3ystn97nbx3980000gn/T/ipykernel_92962/665709683.py:48: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  assistant_message = {\"role\": \"assistant\", \"content\": model_response, \"timestamp\": datetime.utcnow()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inserted successfully with ID: 67b2702d52428ec61e7289f9\n",
      "INFO:     127.0.0.1:54880 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "Data inserted successfully with ID: 67b2705552428ec61e7289fa\n",
      "INFO:     127.0.0.1:54900 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "Data inserted successfully with ID: 67b2865852428ec61e7289fb\n",
      "INFO:     127.0.0.1:56232 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "Data inserted successfully with ID: 67b286dc52428ec61e7289fc\n",
      "INFO:     127.0.0.1:56286 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "Data inserted successfully with ID: 67b2870152428ec61e7289fd\n",
      "INFO:     127.0.0.1:56291 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "Data inserted successfully with ID: 67b2872352428ec61e7289fe\n",
      "INFO:     127.0.0.1:56294 - \"POST /generate HTTP/1.1\" 200 OK\n",
      "Data inserted successfully with ID: 67b2874952428ec61e7289ff\n",
      "INFO:     127.0.0.1:56297 - \"POST /generate HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Shutting down\n",
      "INFO:     Waiting for application shutdown.\n",
      "INFO:     Application shutdown complete.\n",
      "INFO:     Finished server process [92962]\n"
     ]
    }
   ],
   "source": [
    "from fastapi import FastAPI, HTTPException\n",
    "from pydantic import BaseModel\n",
    "import ollama\n",
    "import nest_asyncio\n",
    "import uvicorn\n",
    "from datetime import datetime\n",
    "from pymongo import MongoClient\n",
    "from utils import mongo_module\n",
    "\n",
    "# MongoDB Setup\n",
    "URI = mongo_module.mongo_creds_from_config()\n",
    "client = mongo_module.create_mongo_client(URI)\n",
    "\n",
    "# Initialize FastAPI\n",
    "app = FastAPI()\n",
    "\n",
    "# Pydantic model for input validation\n",
    "class ChatRequest(BaseModel):\n",
    "    user_id: str\n",
    "    prompt: str\n",
    "\n",
    "@app.post(\"/generate\")\n",
    "def generate(request: ChatRequest):\n",
    "    user_id = request.user_id\n",
    "    prompt = request.prompt\n",
    "    timestamp = datetime.utcnow()\n",
    "\n",
    "    # Prepare the user message with timestamp\n",
    "    user_message = {\"role\": \"user\", \"content\": prompt, \"timestamp\": timestamp}\n",
    "\n",
    "    # Fetch previous chat history from MongoDB\n",
    "    chat_history = list(mongo_module.get_conversation(client, \"personalAI\", \"chatHistory\", user_id))\n",
    "\n",
    "    # Append the new message\n",
    "    chat_history.append(user_message)\n",
    "\n",
    "    # Prepare system message\n",
    "    system_prompt = {\"role\": \"system\", \"content\": \"You are a patient and knowledgeable teacher.\"}\n",
    "\n",
    "    # Build message list for LLM\n",
    "    messages = [system_prompt] + chat_history\n",
    "\n",
    "    # Call the LLM model\n",
    "    response = ollama.chat(model=\"llama3.2:1b\", messages=messages)\n",
    "    model_response = response['message']['content']\n",
    "\n",
    "    # Store assistant response with timestamp\n",
    "    assistant_message = {\"role\": \"assistant\", \"content\": model_response, \"timestamp\": datetime.utcnow()}\n",
    "    chat_history.append(assistant_message)\n",
    "\n",
    "    # Store updated chat history in MongoDB\n",
    "    mongo_module.insert_data(client, \"personalAI\", \"chatHistory\", {\n",
    "        \"user_id\": user_id,\n",
    "        \"conversation\": chat_history\n",
    "    })\n",
    "\n",
    "    # Return response including model response, chat history, and timestamp\n",
    "    return {\n",
    "        \"response\": model_response,\n",
    "        \"chat_history\": chat_history,\n",
    "        \"timestamp\": timestamp  # Explicitly return the timestamp here\n",
    "    }\n",
    "\n",
    "\n",
    "@app.get(\"/history/{user_id}\")\n",
    "def get_chat_history(user_id: str):\n",
    "    chat_history = mongo_module.get_conversation(client, \"personalAI\", \"chatHistory\", user_id)\n",
    "    # Only keep the last 10 conversations\n",
    "    chat_history = chat_history[-10:]\n",
    "    return {\"history\": chat_history}\n",
    "\n",
    "\n",
    "@app.post(\"/reset\")\n",
    "def reset_session(user_id: str):\n",
    "    result = mongo_module.delete_data(client, \"personalAI\", \"chatHistory\", {\"user_id\": user_id})\n",
    "    \n",
    "    if result.deleted_count > 0:\n",
    "        return {\"message\": f\"Session for {user_id} has been reset.\"}\n",
    "    else:\n",
    "        raise HTTPException(status_code=404, detail=\"Session not found\")\n",
    "\n",
    "# Apply nest_asyncio for running in Jupyter (only needed if using Jupyter)\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Start FastAPI server (use only when running script directly)\n",
    "if __name__ == \"__main__\":\n",
    "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
